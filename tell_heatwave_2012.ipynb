{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# TELL Analysis of 2012 Heat Wave\n",
    "\n",
    "This notebook processes and makes plots of the temporal evolution of load during the course of the 2012 heat wave in the U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing required packages and information about your operating system:\n",
    "import os \n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc0f66-ba83-47d4-b161-0b1ad076064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top-level data input and output directories:\n",
    "tell_data_input_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/data/tell_data/'\n",
    "image_output_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/plots'\n",
    "\n",
    "# If the \"image_output_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(image_output_dir):\n",
    "   os.makedirs(image_output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6286e-0b62-416d-93ff-8a072d14bc13",
   "metadata": {},
   "source": [
    "## Set the Balancing Authority and Scenario You Want to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26d201-3748-4f87-9c60-f4f402be86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the abbreviation for the BA you want to analyze:\n",
    "ba_to_plot = 'PSCO'\n",
    "\n",
    "# Set the scenario you want to analyze:\n",
    "scenario = 'without_population_effects'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4c982-584f-407f-88b9-3ee6844ddd0a",
   "metadata": {},
   "source": [
    "## Process the Load Data for Time Series Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb9b95-9ca5-4a30-af3e-365be97e741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the historical load data:\n",
    "if scenario == 'with_population_effects': \n",
    "   hist_df = pd.read_csv((tell_data_input_dir + 'with_population_effects/' + 'BA_Loads_2012_With_Population_Effects.csv'))\n",
    "   fut_df = pd.read_csv((tell_data_input_dir + 'with_population_effects/' + 'BA_Loads_2052_With_Population_Effects.csv'))\n",
    "else:\n",
    "   hist_df = pd.read_csv((tell_data_input_dir + 'without_population_effects/' + 'BA_Loads_2012_Without_Population_Effects.csv'))\n",
    "   fut_df = pd.read_csv((tell_data_input_dir + 'without_population_effects/' + 'BA_Loads_2052_Without_Population_Effects.csv'))\n",
    "    \n",
    "hist_df = hist_df.loc[hist_df['BA'].isin([ba_to_plot])].copy()\n",
    "hist_df['Year'] = pd.DatetimeIndex(hist_df['Time_UTC']).year\n",
    "hist_df['Month'] = pd.DatetimeIndex(hist_df['Time_UTC']).month\n",
    "hist_df['Day'] = pd.DatetimeIndex(hist_df['Time_UTC']).day\n",
    "hist_df['Hour'] = pd.DatetimeIndex(hist_df['Time_UTC']).hour\n",
    "\n",
    "fut_df = fut_df.loc[fut_df['BA'].isin([ba_to_plot])].copy()\n",
    "fut_df['Year'] = pd.DatetimeIndex(fut_df['Time_UTC']).year\n",
    "fut_df['Month'] = pd.DatetimeIndex(fut_df['Time_UTC']).month\n",
    "fut_df['Day'] = pd.DatetimeIndex(fut_df['Time_UTC']).day\n",
    "fut_df['Hour'] = pd.DatetimeIndex(fut_df['Time_UTC']).hour\n",
    "    \n",
    "plot_df = pd.merge(hist_df, fut_df, how='left', on=['BA', 'Month', 'Day', 'Hour'])\n",
    "plot_df['date'] = plot_df[[\"Year_x\",\"Month\",\"Day\",\"Hour\"]].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")\n",
    "plot_df['Time_UTC'] = pd.to_datetime(plot_df['date'], format='%Y-%m-%d-%H')\n",
    "\n",
    "# Compute the normalized loads:\n",
    "plot_df['rcp45cooler_ssp3_norm'] = 100 * (plot_df['rcp45cooler_ssp3'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp45cooler_ssp5_norm'] = 100 * (plot_df['rcp45cooler_ssp5'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp45hotter_ssp3_norm'] = 100 * (plot_df['rcp45hotter_ssp3'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp45hotter_ssp5_norm'] = 100 * (plot_df['rcp45hotter_ssp5'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp85cooler_ssp3_norm'] = 100 * (plot_df['rcp85cooler_ssp3'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp85cooler_ssp5_norm'] = 100 * (plot_df['rcp85cooler_ssp5'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp85hotter_ssp3_norm'] = 100 * (plot_df['rcp85hotter_ssp3'].div(plot_df['historic']) - 1)\n",
    "plot_df['rcp85hotter_ssp5_norm'] = 100 * (plot_df['rcp85hotter_ssp5'].div(plot_df['historic']) - 1)\n",
    "\n",
    "# Only keep the columns that are needed:\n",
    "plot_df = plot_df[['Time_UTC', 'historic', \n",
    "                   'rcp45cooler_ssp3', 'rcp45cooler_ssp3_norm', \n",
    "                   'rcp45cooler_ssp5', 'rcp45cooler_ssp5_norm',\n",
    "                   'rcp45hotter_ssp3', 'rcp45hotter_ssp3_norm',\n",
    "                   'rcp45hotter_ssp5', 'rcp45hotter_ssp5_norm',\n",
    "                   'rcp85cooler_ssp3', 'rcp85cooler_ssp3_norm', \n",
    "                   'rcp85cooler_ssp5', 'rcp85cooler_ssp5_norm',\n",
    "                   'rcp85hotter_ssp3', 'rcp85hotter_ssp3_norm',\n",
    "                   'rcp85hotter_ssp5', 'rcp85hotter_ssp5_norm']].copy()\n",
    "\n",
    "# Compute the date of the peak historical load:\n",
    "peak_day = plot_df['Time_UTC'].loc[plot_df['historic'].idxmax()] \n",
    "min_date = pd.to_datetime(peak_day) - timedelta(days=3.5)\n",
    "max_date = pd.to_datetime(peak_day) + timedelta(days=3.5)\n",
    "\n",
    "# Compute the annual minimum and maximum loads:\n",
    "min_load = 0.95*plot_df['historic'].min()\n",
    "max_load = 1.05*plot_df['historic'].max()\n",
    "\n",
    "# Return the dataframe:\n",
    "plot_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90e6c9-b46c-44ba-bff8-ed953e3e9ce0",
   "metadata": {},
   "source": [
    "## Make the Time Series Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7facde8-93d7-4785-bcd1-e9ec5ad13371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot:\n",
    "plt.figure(figsize=(25, 20))\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(plot_df['Time_UTC'], plot_df['historic'], color='k', linestyle='-', label='Historical', linewidth=2)\n",
    "plt.plot([min_date, min_date], [min_load, max_load], color='g', linestyle='-', label='Peak Week', linewidth=3)\n",
    "plt.plot([max_date, max_date], [min_load, max_load], color='g', linestyle='-', linewidth=3)\n",
    "plt.ylim([min_load, max_load])\n",
    "plt.xlim([datetime.date(2012, 1, 1), datetime.date(2012, 12, 31)])\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Total Load [MW]')\n",
    "plt.title(('Historical Total Loads in ' + ba_to_plot + ': 2012'))\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(plot_df['Time_UTC'], plot_df['historic'], color='k', linestyle='-', label='Historical', linewidth=2)\n",
    "if scenario == 'with_population_effects':\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45cooler_ssp3'], color='b', linestyle='-', label='rcp45cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45cooler_ssp5'], color='b', linestyle=':', label='rcp45cooler_ssp5', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45hotter_ssp3'], color='cyan', linestyle='-', label='rcp45hotter_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45hotter_ssp5'], color='cyan', linestyle=':', label='rcp45hotter_ssp5', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85cooler_ssp3'], color='orange', linestyle='-', label='rcp85cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85cooler_ssp5'], color='orange', linestyle=':', label='rcp85cooler_ssp5', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85hotter_ssp3'], color='red', linestyle='-', label='rcp85hotter_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85hotter_ssp5'], color='red', linestyle=':', label='rcp85hotter_ssp5', linewidth=3)\n",
    "else:\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45cooler_ssp3'], color='b', linestyle='-', label='rcp45cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45hotter_ssp3'], color='cyan', linestyle='-', label='rcp45hotter_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85cooler_ssp3'], color='orange', linestyle='-', label='rcp85cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85hotter_ssp3'], color='red', linestyle='-', label='rcp85hotter_ssp3', linewidth=3)\n",
    "plt.xlim([min_date, max_date])\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks([])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Projected Total Load [MW]')\n",
    "if scenario == 'with_population_effects':\n",
    "   plt.title(('Absolute Climate and Socioeconomic Impacts in the Peak Load Week: 2052'))\n",
    "else:\n",
    "   plt.title(('Absolute Climate Only Impacts in the Peak Load Week: 2052'))\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "if scenario == 'with_population_effects':\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45cooler_ssp3_norm'], color='b', linestyle='-', label='rcp45cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45cooler_ssp5_norm'], color='b', linestyle=':', label='rcp45cooler_ssp5', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45hotter_ssp3_norm'], color='cyan', linestyle='-', label='rcp45hotter_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45hotter_ssp5_norm'], color='cyan', linestyle=':', label='rcp45hotter_ssp5', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85cooler_ssp3_norm'], color='orange', linestyle='-', label='rcp85cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85cooler_ssp5_norm'], color='orange', linestyle=':', label='rcp85cooler_ssp5', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85hotter_ssp3_norm'], color='red', linestyle='-', label='rcp85hotter_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85hotter_ssp5_norm'], color='red', linestyle=':', label='rcp85hotter_ssp5', linewidth=3)\n",
    "else:\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45cooler_ssp3_norm'], color='b', linestyle='-', label='rcp45cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp45hotter_ssp3_norm'], color='cyan', linestyle='-', label='rcp45hotter_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85cooler_ssp3_norm'], color='orange', linestyle='-', label='rcp85cooler_ssp3', linewidth=3)\n",
    "   plt.plot(plot_df['Time_UTC'], plot_df['rcp85hotter_ssp3_norm'], color='red', linestyle='-', label='rcp85hotter_ssp3', linewidth=3)\n",
    "plt.plot([min_date, max_date], [0, 0], color='k', linestyle='-', linewidth=3)\n",
    "plt.xlim([min_date, max_date])\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks([])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Load Change Relative to 2012 [%]')\n",
    "if scenario == 'with_population_effects':\n",
    "   plt.title(('Relative Climate and Socioeconomic Impacts in the Peak Load Week: 2052'))\n",
    "else:\n",
    "   plt.title(('Relative Climate Only Impacts in the Peak Load Week: 2052'))\n",
    "\n",
    "if scenario == 'with_population_effects':\n",
    "   filename = ('2012_heatwave_' + ba_to_plot + '_with_population_effects.png')\n",
    "else:\n",
    "   filename = ('2012_heatwave_' + ba_to_plot + '_without_population_effects.png')\n",
    "\n",
    "plt.savefig(os.path.join(image_output_dir, filename), dpi=300, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332982d-d6ab-4750-a58b-c24d2517ca2c",
   "metadata": {},
   "source": [
    "## Process the Load Data for BA Histogram Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe0c0d-0de1-432a-9bbf-47e3f4f62516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the scenario you want to analyze:\n",
    "scenario_to_analze = 'rcp85hotter_ssp5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9779b-cb62-4241-93e7-75ae574babda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the historical load data with population effects:\n",
    "hist_with_df = pd.read_csv((tell_data_input_dir + 'with_population_effects/' + 'BA_Loads_2012_With_Population_Effects.csv'))\n",
    "hist_with_df.rename(columns={'historic': 'historic_with_pop'}, inplace=True)\n",
    "hist_with_df['Year'] = pd.DatetimeIndex(hist_with_df['Time_UTC']).year\n",
    "hist_with_df['Month'] = pd.DatetimeIndex(hist_with_df['Time_UTC']).month\n",
    "hist_with_df['Day'] = pd.DatetimeIndex(hist_with_df['Time_UTC']).day\n",
    "hist_with_df['Hour'] = pd.DatetimeIndex(hist_with_df['Time_UTC']).hour\n",
    "\n",
    "# Read in the projected load data with population effects:\n",
    "fut_with_df = pd.read_csv((tell_data_input_dir + 'with_population_effects/' + 'BA_Loads_2052_With_Population_Effects.csv'))\n",
    "fut_with_df = fut_with_df[['BA', 'Time_UTC', scenario_to_analze]].copy()\n",
    "fut_with_df.rename(columns={scenario_to_analze: 'future_with_pop'}, inplace=True)\n",
    "fut_with_df['Year'] = pd.DatetimeIndex(fut_with_df['Time_UTC']).year\n",
    "fut_with_df['Month'] = pd.DatetimeIndex(fut_with_df['Time_UTC']).month\n",
    "fut_with_df['Day'] = pd.DatetimeIndex(fut_with_df['Time_UTC']).day\n",
    "fut_with_df['Hour'] = pd.DatetimeIndex(fut_with_df['Time_UTC']).hour\n",
    "    \n",
    "# Read in the historical load data without population effects:\n",
    "hist_without_df = pd.read_csv((tell_data_input_dir + 'without_population_effects/' + 'BA_Loads_2012_Without_Population_Effects.csv'))\n",
    "hist_without_df.rename(columns={'historic': 'historic_without_pop'}, inplace=True)\n",
    "hist_without_df['Year'] = pd.DatetimeIndex(hist_without_df['Time_UTC']).year\n",
    "hist_without_df['Month'] = pd.DatetimeIndex(hist_without_df['Time_UTC']).month\n",
    "hist_without_df['Day'] = pd.DatetimeIndex(hist_without_df['Time_UTC']).day\n",
    "hist_without_df['Hour'] = pd.DatetimeIndex(hist_without_df['Time_UTC']).hour\n",
    "\n",
    "# Read in the projected load data without population effects:\n",
    "fut_without_df = pd.read_csv((tell_data_input_dir + 'without_population_effects/' + 'BA_Loads_2052_Without_Population_Effects.csv'))\n",
    "fut_without_df = fut_without_df[['BA', 'Time_UTC', scenario_to_analze]].copy()\n",
    "fut_without_df.rename(columns={scenario_to_analze: 'future_without_pop'}, inplace=True)\n",
    "fut_without_df['Year'] = pd.DatetimeIndex(fut_without_df['Time_UTC']).year\n",
    "fut_without_df['Month'] = pd.DatetimeIndex(fut_without_df['Time_UTC']).month\n",
    "fut_without_df['Day'] = pd.DatetimeIndex(fut_without_df['Time_UTC']).day\n",
    "fut_without_df['Hour'] = pd.DatetimeIndex(fut_without_df['Time_UTC']).hour\n",
    "\n",
    "# Merge the datasets together based on common BA, year, month, day, and hour combinations:\n",
    "analysis_df = pd.merge(hist_with_df, fut_with_df, how='left', on=['BA', 'Month', 'Day', 'Hour'])\n",
    "analysis_df = analysis_df[['BA', 'Year_x', 'Month', 'Day', 'Hour', 'historic_with_pop', 'future_with_pop']].copy()\n",
    "analysis_df = pd.merge(analysis_df, hist_without_df, how='left', on=['BA', 'Month', 'Day', 'Hour'])\n",
    "analysis_df = analysis_df[['BA', 'Year_x', 'Month', 'Day', 'Hour', 'historic_with_pop', 'future_with_pop', 'historic_without_pop']].copy()\n",
    "analysis_df = pd.merge(analysis_df, fut_without_df, how='left', on=['BA', 'Month', 'Day', 'Hour'])\n",
    "analysis_df = analysis_df[['BA', 'Year_x', 'Month', 'Day', 'Hour', 'historic_with_pop', 'future_with_pop', 'historic_without_pop', 'future_without_pop']].copy()\n",
    "\n",
    "# Convert the time to a datetime variable:\n",
    "analysis_df['date'] = analysis_df[['Year_x', 'Month', 'Day', 'Hour']].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")\n",
    "analysis_df['Time_UTC'] = pd.to_datetime(analysis_df['date'], format='%Y-%m-%d-%H')\n",
    "\n",
    "# Compute the normalized loads:\n",
    "analysis_df['norm_with_pop'] = 100 * (analysis_df['future_with_pop'].div(analysis_df['historic_with_pop']) - 1)\n",
    "analysis_df['norm_without_pop'] = 100 * (analysis_df['future_without_pop'].div(analysis_df['historic_without_pop']) - 1)\n",
    "\n",
    "# Only keep the columns that are needed:\n",
    "analysis_df = analysis_df[['BA', 'Time_UTC', \n",
    "                           'historic_with_pop', 'future_with_pop', 'norm_with_pop',\n",
    "                           'historic_without_pop', 'future_without_pop', 'norm_without_pop']].copy()\n",
    "\n",
    "# Return the dataframe\n",
    "analysis_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdf729-c205-412b-9b10-7e4c362c47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all of the BAs in the \"analysis_df\":\n",
    "bas = analysis_df['BA'].unique()\n",
    "\n",
    "# Create an empty dataframe and store the results:\n",
    "ba_df = pd.DataFrame()\n",
    "    \n",
    "# Loop over the BAs and compute their mean effects:\n",
    "for i in range(len(bas)):\n",
    "    # Subset to just the data for the BA being processed:\n",
    "    subset_df = analysis_df[analysis_df['BA'].isin([bas[i]])].copy()\n",
    "    \n",
    "    # Compute the date of the peak historical load:\n",
    "    peak_day = subset_df['Time_UTC'].loc[subset_df['historic_with_pop'].idxmax()] \n",
    "    min_date = pd.to_datetime(peak_day) - timedelta(days=3.5)\n",
    "    max_date = pd.to_datetime(peak_day) + timedelta(days=3.5)\n",
    "    \n",
    "    # Subset to only the week around the historical peak load value:\n",
    "    peak_df = subset_df.loc[(subset_df['Time_UTC'] >= min_date) & (subset_df['Time_UTC'] < max_date)]\n",
    "    \n",
    "    # Output the mean difference:\n",
    "    ba_df.loc[i, 'BA'] = bas[i]\n",
    "    ba_df.loc[i, 'Mean_With_Pop'] = subset_df['norm_with_pop'].mean().round(2)\n",
    "    ba_df.loc[i, 'Max_With_Pop'] = subset_df['norm_with_pop'].max().round(2)\n",
    "    ba_df.loc[i, 'Peak_With_Pop'] = peak_df['norm_with_pop'].mean().round(2)\n",
    "    ba_df.loc[i, 'Mean_Without_Pop'] = subset_df['norm_without_pop'].mean().round(2)\n",
    "    ba_df.loc[i, 'Max_Without_Pop'] = subset_df['norm_without_pop'].max().round(2)\n",
    "    ba_df.loc[i, 'Peak_Without_Pop'] = peak_df['norm_without_pop'].mean().round(2)\n",
    "\n",
    "# Subset the dataframe to only BAs in the WECC:\n",
    "ba_df = ba_df[ba_df['BA'].isin(['AVA','AZPS','BANC','BPAT','CHPD','CISO','DEAA','DOPD','EPE',\n",
    "                                'GCPD','IID','IPCO','LDWP','NEVP','NWMT','PACE','PACW','PGE',\n",
    "                                'PNM','PSCO','PSEI','SCL','SRP','TEPC','TIDC','TPWR','WACM',\n",
    "                                'WALC','WAUW'])]\n",
    "    \n",
    "# Return the dataframe:\n",
    "ba_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b65b77-e4b0-49d5-832f-db4a28e762d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an x-axis the length of the dataframe to be used in plotting:\n",
    "x_axis = np.arange(len(ba_df))\n",
    "\n",
    "# Make the plot:\n",
    "plt.figure(figsize=(25, 20))\n",
    "plt.subplot(221)\n",
    "plt.bar(x_axis, ba_df.sort_values(by=['Mean_With_Pop'], ascending=True)['Mean_With_Pop'], 0.75)\n",
    "plt.xticks(x_axis, ba_df.sort_values(by=['Mean_With_Pop'], ascending=True)['BA'], rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel('Balancing Authority')\n",
    "plt.ylabel('Mean Load Change in 2052 Relative to 2012 [%]')\n",
    "plt.title('Mean Effect with Climate and Socioeconomic Impacts: ' + scenario_to_analze)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.bar(x_axis, ba_df.sort_values(by=['Mean_Without_Pop'], ascending=True)['Mean_Without_Pop'], 0.75)\n",
    "plt.xticks(x_axis, ba_df.sort_values(by=['Mean_Without_Pop'], ascending=True)['BA'], rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel('Balancing Authority')\n",
    "plt.ylabel('Mean Load Change in 2052 Relative to 2012 [%]')\n",
    "plt.title('Mean Effect with Climate Only Impacts: ' + scenario_to_analze)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.bar(x_axis, ba_df.sort_values(by=['Peak_With_Pop'], ascending=True)['Peak_With_Pop'], 0.75)\n",
    "plt.xticks(x_axis, ba_df.sort_values(by=['Peak_With_Pop'], ascending=True)['BA'], rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel('Balancing Authority')\n",
    "plt.ylabel('Mean Load Change in 2052 Relative to 2012 [%]')\n",
    "plt.title('Peak Week Effect with Climate and Socioeconomic Impacts')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.bar(x_axis, ba_df.sort_values(by=['Peak_Without_Pop'], ascending=True)['Peak_Without_Pop'], 0.75)\n",
    "plt.xticks(x_axis, ba_df.sort_values(by=['Peak_Without_Pop'], ascending=True)['BA'], rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel('Balancing Authority')\n",
    "plt.ylabel('Mean Load Change in 2052 Relative to 2012 [%]')\n",
    "plt.title('Peak Week Effect with Climate Only Impacts')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.4)\n",
    "\n",
    "filename = ('BA_Comparison_2052_' + scenario_to_analze + '.png')\n",
    "\n",
    "plt.savefig(os.path.join(image_output_dir, filename), dpi=300, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b6dab-5503-4cf7-9a6f-25a73d5a5e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
