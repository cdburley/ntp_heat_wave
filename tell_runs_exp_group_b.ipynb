{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TELL Runs for the National Transmission Planning (NTP) Project\n",
    "\n",
    "This notebook executes the initial set of runs of the TELL model for the NTP project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tell.package_data import get_ba_abbreviations\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc0f66-ba83-47d4-b161-0b1ad076064c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the top-level directory and the subdirectory where the data will be stored:\n",
    "current_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs'\n",
    "tell_data_dir = os.path.join(current_dir, r'tell_data')\n",
    "\n",
    "# If the \"tell_data_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_data_dir):\n",
    "   os.makedirs(tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a037554",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the MLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6b851-29c9-4a1b-a149-ee341f1af5cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a list of BA abbreviations to process:\n",
    "ba_abbrev_list = tell.get_balancing_authority_to_model_dict().keys()\n",
    "\n",
    "scenario_to_process = 'historic'\n",
    "\n",
    "# Run the MLP prediction step for the list of BAs using parallel processing streams:\n",
    "for year_to_process in range(1980,2020,1):\n",
    "    pdf = tell.predict_batch(target_region_list = ba_abbrev_list,\n",
    "                             year = year_to_process,\n",
    "                             data_dir = os.path.join(tell_data_dir, r'wrf_to_tell_data', scenario_to_process),\n",
    "                             datetime_field_name = 'Time_UTC',\n",
    "                             save_prediction = True,\n",
    "                             prediction_output_directory = os.path.join(tell_data_dir, r'outputs', r'mlp_output', scenario_to_process),\n",
    "                             n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9048639",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run the Forward Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afab9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run the TELL model forward in time for a given year in five year increments out to 2100:\n",
    "for year in range(1980,2020,1):\n",
    "    summary_df, ba_time_series_df, state_time_series_df = tell.execute_forward(year_to_process = str(year),\n",
    "                                                                               gcam_target_year = str(year), \n",
    "                                                                               scenario_to_process = 'historic',\n",
    "                                                                               data_output_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/outputs/tell_output',\n",
    "                                                                               gcam_usa_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/gcamusa_data',\n",
    "                                                                               map_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/ba_service_territory_data',\n",
    "                                                                               mlp_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/outputs/mlp_output',\n",
    "                                                                               pop_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/population_data',\n",
    "                                                                               save_county_data = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2c129-ce17-4f26-b8ff-c0e61258cc52",
   "metadata": {},
   "source": [
    "## Clean Up the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836f561-648e-40c3-8849-d573cdc8a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to aggregate the MLP output into a single file:\n",
    "def aggregate_mlp_output(data_input_dir: str):\n",
    "    \n",
    "    # Create a list of all county meteorology files in the input directory:\n",
    "    list_of_files = glob(f'{data_input_dir}/*_mlp_output.csv')\n",
    "    \n",
    "    # Loop over that list and extract the population-weighted T2 values:\n",
    "    for file in range(len(list_of_files)):\n",
    "        # Read in the .csv file:\n",
    "        load_df = pd.read_csv(list_of_files[file])\n",
    "        \n",
    "        # Rename the load variable for clarity:\n",
    "        load_df.rename(columns={'Load': 'Load_MWh'}, inplace=True)\n",
    "        \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if file == 0:\n",
    "            output_df = load_df\n",
    "        else:\n",
    "            output_df = pd.concat([output_df, load_df])\n",
    "    \n",
    "    # Reorder and sort the columns:\n",
    "    output_df = output_df[['BA', 'Time_UTC', 'Load_MWh']]\n",
    "    output_df = output_df.sort_values(['BA', 'Time_UTC'])\n",
    "    \n",
    "    # Generate the .csv output file name:\n",
    "    csv_output_filename = os.path.join(data_input_dir, 'All_BA_Output.csv')\n",
    "\n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd59760-9df2-4c8e-a89c-9b75ed341fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the directory to aggregate:\n",
    "data_input_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/data/tell_data/without_population_effects/rcp85hotter_ssp5'\n",
    "\n",
    "# Aggregate the individual MLP output files into a single .csv file:\n",
    "aggregate_mlp_output(data_input_dir = data_input_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e51d6e-e678-4801-81ab-e9b71a2352b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the top-level data input and output directory:\n",
    "data_input_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/data/tell_data/without_population_effects'\n",
    "\n",
    "# Read in the input files, rename the load variable, and aggregate the data across scenarios:\n",
    "historic_df = pd.read_csv((data_input_dir + '/historic/' + 'All_BA_Output.csv'))\n",
    "historic_df.rename(columns={'Load_MWh': 'historic'}, inplace=True)\n",
    "\n",
    "# Generate the .csv output file name:\n",
    "csv_output_filename = os.path.join(data_input_dir, 'BA_Loads_2006_Without_Population_Effects.csv')\n",
    "\n",
    "# Write out the dataframe to a .csv file:\n",
    "historic_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "historic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3bea91-9db6-4495-be40-b0ab7a982d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the top-level data input and output directory:\n",
    "data_input_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/data/tell_data/without_population_effects'\n",
    "\n",
    "# Read in the input files, rename the load variable, and aggregate the data across scenarios:\n",
    "rcp45cooler_ssp3 = pd.read_csv((data_input_dir + '/rcp45cooler_ssp3/' + 'All_BA_Output.csv'))\n",
    "rcp45cooler_ssp3.rename(columns={'Load_MWh': 'rcp45cooler_ssp3'}, inplace=True)\n",
    "output_df = rcp45cooler_ssp3.copy()\n",
    "\n",
    "rcp45cooler_ssp5 = pd.read_csv((data_input_dir + '/rcp45cooler_ssp5/' + 'All_BA_Output.csv'))\n",
    "rcp45cooler_ssp5.rename(columns={'Load_MWh': 'rcp45cooler_ssp5'}, inplace=True)\n",
    "output_df = output_df.merge(rcp45cooler_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp45hotter_ssp3 = pd.read_csv((data_input_dir + '/rcp45hotter_ssp3/' + 'All_BA_Output.csv'))\n",
    "rcp45hotter_ssp3.rename(columns={'Load_MWh': 'rcp45hotter_ssp3'}, inplace=True)\n",
    "output_df = output_df.merge(rcp45hotter_ssp3, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp45hotter_ssp5 = pd.read_csv((data_input_dir + '/rcp45hotter_ssp5/' + 'All_BA_Output.csv'))\n",
    "rcp45hotter_ssp5.rename(columns={'Load_MWh': 'rcp45hotter_ssp5'}, inplace=True)\n",
    "output_df = output_df.merge(rcp45hotter_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85cooler_ssp3 = pd.read_csv((data_input_dir + '/rcp85cooler_ssp3/' + 'All_BA_Output.csv'))\n",
    "rcp85cooler_ssp3.rename(columns={'Load_MWh': 'rcp85cooler_ssp3'}, inplace=True)\n",
    "output_df = output_df.merge(rcp85cooler_ssp3, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85cooler_ssp5 = pd.read_csv((data_input_dir + '/rcp85cooler_ssp5/' + 'All_BA_Output.csv'))\n",
    "rcp85cooler_ssp5.rename(columns={'Load_MWh': 'rcp85cooler_ssp5'}, inplace=True)\n",
    "output_df = output_df.merge(rcp85cooler_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85hotter_ssp3 = pd.read_csv((data_input_dir + '/rcp85hotter_ssp3/' + 'All_BA_Output.csv'))\n",
    "rcp85hotter_ssp3.rename(columns={'Load_MWh': 'rcp85hotter_ssp3'}, inplace=True)\n",
    "output_df = output_df.merge(rcp85hotter_ssp3, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85hotter_ssp5 = pd.read_csv((data_input_dir + '/rcp85hotter_ssp5/' + 'All_BA_Output.csv'))\n",
    "rcp85hotter_ssp5.rename(columns={'Load_MWh': 'rcp85hotter_ssp5'}, inplace=True)\n",
    "output_df = output_df.merge(rcp85hotter_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "# Generate the .csv output file name:\n",
    "csv_output_filename = os.path.join(data_input_dir, 'BA_Loads_2046_Without_Population_Effects.csv')\n",
    "\n",
    "# Write out the dataframe to a .csv file:\n",
    "output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93051f53-5893-4b5e-b15c-af26282b5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the top-level data input and output directory:\n",
    "data_input_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/data/tell_data/with_population_effects'\n",
    "\n",
    "# Read in the input files, rename the load variable, and aggregate the data across scenarios:\n",
    "historic_df = pd.read_csv((data_input_dir + '/historic/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2006_Scaled_2006.csv'))\n",
    "historic_df.rename(columns={'Scaled_TELL_BA_Load_MWh': 'historic','BA_Code': 'BA'}, inplace=True)\n",
    "historic_df = historic_df[['BA', 'Time_UTC', 'historic']]\n",
    "\n",
    "# Generate the .csv output file name:\n",
    "csv_output_filename = os.path.join(data_input_dir, 'BA_Loads_2006_With_Population_Effects.csv')\n",
    "\n",
    "# Write out the dataframe to a .csv file:\n",
    "historic_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "historic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f09eb-140b-481b-9743-fd63496d341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the top-level data input and output directory:\n",
    "data_input_dir =  '/Users/burl878/Documents/Code/code_repos/ntp_heat_wave/data/tell_data/with_population_effects'\n",
    "\n",
    "# Read in the input files, rename the load variable, and aggregate the data across scenarios:\n",
    "rcp45cooler_ssp3 = pd.read_csv((data_input_dir + '/rcp45cooler_ssp3/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp45cooler_ssp3.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp45cooler_ssp3','BA_Code': 'BA'}, inplace=True)\n",
    "rcp45cooler_ssp3 = rcp45cooler_ssp3[['BA', 'Time_UTC', 'rcp45cooler_ssp3']]\n",
    "output_df = rcp45cooler_ssp3.copy()\n",
    "\n",
    "rcp45cooler_ssp5 = pd.read_csv((data_input_dir + '/rcp45cooler_ssp5/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp45cooler_ssp5.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp45cooler_ssp5','BA_Code': 'BA'}, inplace=True)\n",
    "rcp45cooler_ssp5 = rcp45cooler_ssp5[['BA', 'Time_UTC', 'rcp45cooler_ssp5']]\n",
    "output_df = output_df.merge(rcp45cooler_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp45hotter_ssp3 = pd.read_csv((data_input_dir + '/rcp45hotter_ssp3/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp45hotter_ssp3.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp45hotter_ssp3','BA_Code': 'BA'}, inplace=True)\n",
    "rcp45hotter_ssp3 = rcp45hotter_ssp3[['BA', 'Time_UTC', 'rcp45hotter_ssp3']]\n",
    "output_df = output_df.merge(rcp45hotter_ssp3, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp45hotter_ssp5 = pd.read_csv((data_input_dir + '/rcp45hotter_ssp5/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp45hotter_ssp5.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp45hotter_ssp5','BA_Code': 'BA'}, inplace=True)\n",
    "rcp45hotter_ssp5 = rcp45hotter_ssp5[['BA', 'Time_UTC', 'rcp45hotter_ssp5']]\n",
    "output_df = output_df.merge(rcp45hotter_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85cooler_ssp3 = pd.read_csv((data_input_dir + '/rcp85cooler_ssp3/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp85cooler_ssp3.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp85cooler_ssp3','BA_Code': 'BA'}, inplace=True)\n",
    "rcp85cooler_ssp3 = rcp85cooler_ssp3[['BA', 'Time_UTC', 'rcp85cooler_ssp3']]\n",
    "output_df = output_df.merge(rcp85cooler_ssp3, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85cooler_ssp5 = pd.read_csv((data_input_dir + '/rcp85cooler_ssp5/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp85cooler_ssp5.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp85cooler_ssp5','BA_Code': 'BA'}, inplace=True)\n",
    "rcp85cooler_ssp5 = rcp85cooler_ssp5[['BA', 'Time_UTC', 'rcp85cooler_ssp5']]\n",
    "output_df = output_df.merge(rcp85cooler_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85hotter_ssp3 = pd.read_csv((data_input_dir + '/rcp85hotter_ssp3/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp85hotter_ssp3.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp85hotter_ssp3','BA_Code': 'BA'}, inplace=True)\n",
    "rcp85hotter_ssp3 = rcp85hotter_ssp3[['BA', 'Time_UTC', 'rcp85hotter_ssp3']]\n",
    "output_df = output_df.merge(rcp85hotter_ssp3, on=['BA', 'Time_UTC'])\n",
    "\n",
    "rcp85hotter_ssp5 = pd.read_csv((data_input_dir + '/rcp85hotter_ssp5/' + 'TELL_Balancing_Authority_Hourly_Load_Data_2046_Scaled_2046.csv'))\n",
    "rcp85hotter_ssp5.rename(columns={'Scaled_TELL_BA_Load_MWh': 'rcp85hotter_ssp5','BA_Code': 'BA'}, inplace=True)\n",
    "rcp85hotter_ssp5 = rcp85hotter_ssp5[['BA', 'Time_UTC', 'rcp85hotter_ssp5']]\n",
    "output_df = output_df.merge(rcp85hotter_ssp5, on=['BA', 'Time_UTC'])\n",
    "\n",
    "# Generate the .csv output file name:\n",
    "csv_output_filename = os.path.join(data_input_dir, 'BA_Loads_2046_With_Population_Effects.csv')\n",
    "\n",
    "# Write out the dataframe to a .csv file:\n",
    "output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a978a3-ad3e-4c52-a8e3-9539cc6d95c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
